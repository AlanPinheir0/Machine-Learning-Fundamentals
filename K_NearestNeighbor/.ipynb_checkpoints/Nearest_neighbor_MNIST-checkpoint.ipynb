{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor para reconhecimento de dígitos escritos á mão.\n",
    "\n",
    "Neste notebook, vamos construir um classificador que data uma imagem de um dígito manuscrito, atribuirá um label $ l \\in \\{0,1,2,3,4,5,6,7,8,9\\}$. Veremos uma estratégia particularmente simples para esse problema, conhecida como o classificador de vizinho mais próximo\n",
    "\n",
    "requirements:\n",
    "* `numpy`\n",
    "* `matplotlib`\n",
    "* `sklearn` ( Apenas para demosntração)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. O dataset MNIST \n",
    "\n",
    "`MNIST` é um conjunto de dados clássico em aprendizado de máquina, que se trata de imagens 28x28 pixels em escala de cinza que representam dígitos. O conjunto de treinamento original contém 60.000 exemplos e o conjunto de teste contém 10.000 exemplos. Neste notebook, trabalharemos com um subconjunto desses dados: um conjunto de treinamento de 7.500 exemplos e um conjunto de teste de 1.000 exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "## carregando os dados de treino\n",
    "train_data = np.load('MNIST/train_data.npy') \n",
    "train_labels = np.load('MNIST/train_labels.npy')\n",
    "\n",
    "## carregando os dados de teste\n",
    "test_data = np.load('MNIST/test_data.npy')\n",
    "test_labels = np.load('MNIST/test_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wtf is .npy?\n",
    "\n",
    "<a href=\"https://fileinfo.com/extension/npy\"> Clique aqui e descubra ;)</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('train_data.txt',train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printando na tela as dimensões dos dados\n",
    "print(\"Dimensão dos dados de treino: \", np.shape(train_data))\n",
    "print(\"Número de labels do treino: \", len(train_labels))\n",
    "print(\"Dimensão dos dados de teste: \", np.shape(test_data))\n",
    "print(\"Número de labels do teste: \", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculando o número de exemplos de cada dígito\n",
    "train_digits, train_counts = np.unique(train_labels, return_counts=True)\n",
    "print(\"Distribuição dos dados de Treino:\")\n",
    "print(dict(zip(train_digits, train_counts)))\n",
    "\n",
    "test_digits, test_counts = np.unique(test_labels, return_counts=True)\n",
    "print(\"Distribuição dos dados de teste:\")\n",
    "print(dict(zip(test_digits, test_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizando os dados\n",
    "Cada ponto de dados é armazenado como vetor 784-dimensional. Para visualizar um ponto de dados, primeiro modificamos a imagem para 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digit(x):\n",
    "    \"\"\"função que exibe um dígito dada sua representação vetorial\"\"\"\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "   # return\n",
    "\n",
    "def vis_image(index, dataset=\"train\"):\n",
    "    \"\"\"Função que dado um indice e um dataset, mostra a imagem armazenada naquela posição\"\"\"\n",
    "    if(dataset==\"train\"): \n",
    "        show_digit(train_data[index,])\n",
    "        label = train_labels[index]\n",
    "    else:\n",
    "        show_digit(test_data[index,])\n",
    "        label = test_labels[index]\n",
    "    print(\"Label \" + str(label))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## olhando para o primeiro ponto do data set de treino\n",
    "vis_image(0, \"train\")\n",
    "\n",
    "## Olhando para o primeiro ponto do dataset de teste\n",
    "vis_image(0, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distância Euclidiana\n",
    "\n",
    "Para calcular os vizinhos mais próximos em nosso conjunto de dados, precisamos primeiro calcular as distâncias entre os pontos de dados. Uma função de distância natural é a distância euclidiana: para dois vetores $x, y \\in \\mathbb{R}^d$, a distância euclidiana entre eles é definida como\n",
    "$$\\|x - y\\| = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
    "Muitas vezes omitimos a raiz quadrada e simplesmente calculamos a distância euclidiana _quadrada_:\n",
    "$$\\|x - y\\|^2 = \\sum_{i=1}^d (x_i - y_i)^2.$$\n",
    "Para os cálculos dos vizinhos mais próximos, os dois são equivalentes: para três vetores $x, y, z \\in \\mathbb{R}^d$, nós temos $\\|x - y\\| \\leq \\|x - z\\|$ se e somente se $\\|x - y\\|^2 \\leq \\|x - z\\|^2$.\n",
    "\n",
    "Agora só precisamos ser capazes de calcular a distância euclidiana ao quadrado. A função a seguir faz isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computes squared Euclidean distance between two vectors.\n",
    "def squared_dist(x,y):\n",
    "    return np.sum(np.square(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calcular a distância entre os vetores ( l2)\n",
    "#print(\"Distancia do 1 pro 2: \", squared_dist(train_data[1,],train_data[2,]))\n",
    "#print(\"Distancia do 1 pro 3: \", squared_dist(train_data[1,],train_data[3,]))\n",
    "#print(\"Distancia do 1 pro 1: \", squared_dist(train_data[1,],train_data[1,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculando os vizinhos mais próximos:\n",
    "\n",
    "Agora que temos uma função de distância definida, podemos agora passar para a classificação de vizinho mais próximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_NN(x):\n",
    "    '''Função recebe um vetor x e retorn o indice do seu vizinho mais próximo, presente no dataset'''\n",
    "    \n",
    "    # calcula a distancia de x para cada linha (vetor) do dataset\n",
    "    distances = [squared_dist(x,train_data[i,]) for i in range(len(train_labels))]\n",
    "    \n",
    "    # retorna o indice da menor distância\n",
    "    return np.argmin(distances)\n",
    "\n",
    "def NN_classifier(x):\n",
    "    \"\"\"Pega um vetor x e retorna o label do seu vizinho mais próximo no dataset\"\"\"\n",
    "    # Recebe o index do vizinho mais proximo\n",
    "    index = find_NN(x)\n",
    "    # Retorna a classe dele\n",
    "    return train_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## casos de sucesso:\n",
    "print(\"Um caso de sucesso:\")\n",
    "print(\"Classificação do 1-NN: \", NN_classifier(test_data[0,]))\n",
    "print(\"Label verddeiro: \", test_labels[0])\n",
    "print(\"A imagem de teste:\")\n",
    "vis_image(0, \"test\")\n",
    "print(\"A imagem do vizinho mais próximo:\")\n",
    "vis_image(find_NN(test_data[0,]), \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deu ruim:\n",
    "print(\"Um 'deu ruim' :\")\n",
    "print(\"Classificação do 1-NN: \", NN_classifier(test_data[39,]))\n",
    "print(\"O label verdadeiro: \", test_labels[39])\n",
    "print(\"A imagem de teste:\")\n",
    "vis_image(39, \"test\")\n",
    "print(\"A imagem do vizinho mais próximo:\")\n",
    "vis_image(find_NN(test_data[39,]), \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Processando o conjunto completo de testes\n",
    "\n",
    "Agora, vamos aplicar nosso classificador de vizinho mais próximo ao conjunto de dados completo.\n",
    "\n",
    "Observe que, para classificar cada ponto de teste, nosso código passa completamente sobre cada um dos 7500 exemplos de treinamento. Portanto, não devemos esperar que o teste seja muito rápido. O código a seguir leva cerca de 55 segundos no Intel Core i5 7ªGeração de 2,5 GHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classificando cada ponto e cronometrando!\n",
    "t_before = time.time()\n",
    "test_predictions = [NN_classifier(test_data[i,]) for i in range(len(test_labels))]\n",
    "t_after = time.time()\n",
    "\n",
    "## Computando o erro\n",
    "err_positions = np.not_equal(test_predictions, test_labels)\n",
    "error = float(np.sum(err_positions))/len(test_labels)\n",
    "\n",
    "print(\"Erro do nosso classificado: \", error)\n",
    "print(\"Tempo para a classificação (segundos): \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred=test_predictions,y_true=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(10, 100, as_cmap=True)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(confusion_matrix(y_pred=test_predictions,y_true=test_labels),\n",
    "           vmax=100, annot = True,cbar = False,linewidths=.5, cmap = cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como melhorar a performance e diminuir ainda mais o erro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diminuindo o erro...\n",
    "<ol>\n",
    "    <li>Alterar o número de vizinhos, ou seja k > 2</li>\n",
    "    <li>Alterar a função de distância</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mexendo no número de vizinhos\n",
    "\n",
    "# Crie uma função que classifique um dado vetor x, de acordo com  o label mais recorrente de k vizinhos mais pr´ximos \n",
    "\n",
    "def find_k_NN(x,k):\n",
    "    \"\"\"Função recebe um vetor x e um escalar k, e retorna o indice dos k vetores mais próximos no dataset\"\"\"\n",
    "    # dica, use o método argsort do numpy\n",
    "    \n",
    "    ### escreva aqui\n",
    "    \n",
    "def k_NN_classifier(x,k):\n",
    "    \"\"\"Função recebe um vetor x e um escalar k e retorna uma predição para o label de x\"\"\"\n",
    "    \n",
    "    ### escreva aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Qual o número ótimo de vizinhos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualize os resultados..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uma nova noção de simmilaridade...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance... \n",
    "\n",
    "## parta pra ignorancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Faster nearest neighbor methods\n",
    "\n",
    "A realização da classificação de vizinho mais próximo na forma como apresentamos exige uma passagem completa pelo conjunto de treinamento para classificar um único ponto. Se houver pontos de treinamento de $ N $ em $ \\mathbb {R} ^ d $, isso levará $ O (N d) $ tempo.\n",
    "\n",
    "Felizmente, existem métodos mais rápidos de executar o vizinho mais próximo se estivermos dispostos a gastar algum tempo pré-processando o conjunto de treinamento. `scikit-learn` possui implementações rápidas de duas estruturas úteis de dados de vizinhos mais próximos: a ballTree_ e a tree _k-d_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "## Pré-processamento\n",
    "t_before = time.time()\n",
    "ball_tree = BallTree(train_data)\n",
    "t_after = time.time()\n",
    "\n",
    "## Computar o tempo de pre-processamento\n",
    "t_training = t_after - t_before\n",
    "print(\"Tmpo para construir a nova estrutura de dados(segundos): \", t_training)\n",
    "\n",
    "## classificando todo o conjunto de teste\n",
    "t_before = time.time()\n",
    "test_neighbors = np.squeeze(ball_tree.query(test_data, k=1, return_distance=False))\n",
    "ball_tree_predictions = train_labels[test_neighbors]\n",
    "t_after = time.time()\n",
    "\n",
    "## Computando o tempo das predições\n",
    "t_testing = t_after - t_before\n",
    "print(\"Tempo para classificar todo o dataset: \", t_testing)\n",
    "\n",
    "## Verificar se as predições são as mesmas\n",
    "print(\"Ball tree produziu o mesmo resultado que demoramos séculos para obter? \", np.array_equal(test_predictions, ball_tree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "## Pré-processamento\n",
    "t_before = time.time()\n",
    "kd_tree = KDTree(train_data)\n",
    "t_after = time.time()\n",
    "\n",
    "## Computar o tempo de pre-processamento\n",
    "t_training = t_after - t_before\n",
    "print(\"Time to build data structure (seconds): \", t_training)\n",
    "\n",
    "## classificando todo o conjunto de teste\n",
    "t_before = time.time()\n",
    "test_neighbors = np.squeeze(kd_tree.query(test_data, k=1, return_distance=False))\n",
    "kd_tree_predictions = train_labels[test_neighbors]\n",
    "t_after = time.time()\n",
    "\n",
    "## Computando o tempo das predições\n",
    "t_testing = t_after - t_before\n",
    "print(\"Time to classify test set (seconds): \", t_testing)\n",
    "\n",
    "## Verificar se as predições são as mesmas\n",
    "print(\"KD tree produziu o mesmo resultado que demoramos séculos para obter?\", np.array_equal(test_predictions, kd_tree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
